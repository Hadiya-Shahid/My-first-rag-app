{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdfa0593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Desktop\\RAG\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pprint\n",
    "import numpy as np\n",
    "import faiss\n",
    "from typing import List,Dict\n",
    "\n",
    "#Embedding libs(BGE first)\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c258f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path.cwd()\n",
    "data_dir = base / \"data\"\n",
    "index_dir = base / \"vector_store\"\n",
    "index_dir.mkdir(exist_ok=True)\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#embedding model name\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-small-en\"\n",
    "FALLBACK_MDEL_NAME = \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e7c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I assist you today? Is there anything in particular you'd like to discuss or learn about?\n"
     ]
    }
   ],
   "source": [
    "#Ollama\n",
    "import requests\n",
    "import json\n",
    "OLLAMA_API_URL = \"http://127.0.0.1:11434/api/generate\"\n",
    "OLLAMA_MODEL = \"qwen2.5:1.5b\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": OLLAMA_MODEL,\n",
    "    \"prompt\": \"Hello, Ollama!\",\n",
    "}\n",
    "\n",
    "response = requests.post(OLLAMA_API_URL, json=payload)\n",
    "\n",
    "#splitting\n",
    "lines = response.text.splitlines()\n",
    "final_text = \"\"\n",
    "for line in lines:\n",
    "    data = json.loads(line)\n",
    "    final_text += data.get(\"response\", \"\")\n",
    "\n",
    "print(final_text)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620ba1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chuknking \n",
    "chunk_size = 800\n",
    "chunk_overlap = 150\n",
    "k = 5  #number of nearest neighbors to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0534ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embedding model\n",
    "def load_embedding_model():\n",
    "#try to load BGE model, if fails, fallback to MiniLM\n",
    "    try:\n",
    "        print(\"Loading BGE model:\", EMBEDDING_MODEL_NAME)\n",
    "        model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "        print(\"Successfully loaded BGE model.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load BGE model. Error:\", str(e))\n",
    "        print(\"Falling back to MiniLM model:\", FALLBACK_MDEL_NAME)\n",
    "        model = SentenceTransformer(FALLBACK_MDEL_NAME)\n",
    "        print(\"Successfully loaded MiniLM model.\")\n",
    "        return model\n",
    "\n",
    "EMBED_NAME = load_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e45082a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PDFs in data/: [WindowsPath('c:/Users/Administrator/Desktop/RAG/notebook/data/Highlights.pdf')]\n"
     ]
    }
   ],
   "source": [
    "#pdf reading\n",
    "from pypdf import PdfReader\n",
    "def read_pdf(file_path: str) -> str:\n",
    "    reader = PdfReader(file_path)\n",
    "    pages = []\n",
    "    for p in reader.pages:\n",
    "        pages.append(p.extract_text() or \"\")\n",
    "    return \"\\n\".join(pages)\n",
    "\n",
    "print(\"Current PDFs in data/:\", list(data_dir.glob(\"*.[Pp][Dd][Ff]\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c99473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_dir = Path(\"data\")  # folder named \"data\" in your current directory\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e29bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n"
     ]
    }
   ],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12fafd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(data_dir.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94348f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('data/Highlights.pdf')]\n"
     ]
    }
   ],
   "source": [
    "print(list(data_dir.iterdir()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e615f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning\n",
    "def clean_text(text: str):\n",
    "    return \" \".join(text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bd3f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, chunk_size=chunk_size, overlap=chunk_overlap):\n",
    "    text = clean_text(text)\n",
    "    chunks = []       # list to store all chunks\n",
    "    start = 0\n",
    "    length = len(text)\n",
    "    while start < length:\n",
    "        end = min(start + chunk_size, length)\n",
    "        piece = text[start:end].strip()   # chunk text piece\n",
    "        if piece:\n",
    "            chunks.append(piece)\n",
    "        if end == length:\n",
    "            break\n",
    "        start = end - overlap             # sliding window\n",
    "    return chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02c3b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts: List[str]):\n",
    "    embs = EMBED_NAME().encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "    return embs.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315d4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6f2b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chunks created: 65\n"
     ]
    }
   ],
   "source": [
    "pdf_path = list(data_dir.glob(\"*.[Pp][Dd][Ff]\"))[0]\n",
    "\n",
    "text = read_pdf(str(pdf_path))\n",
    "cleaned = clean_text(text)\n",
    "\n",
    "chunks = chunk_text(cleaned)  \n",
    "\n",
    "docs = [\n",
    "    {\"doc_id\": i, \"chunk\": piece}\n",
    "    for i, piece in enumerate(chunks)\n",
    "]\n",
    "\n",
    "print(\"total chunks created:\", len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6401156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(docs: List[Dict]):\n",
    "    \"\"\"docs : docs id and chunks\n",
    "    saves in 1. vector_store/ faiss.index\n",
    "    2. vector_score/metadata.pkl\n",
    "    \"\"\"\n",
    "    index_path = index_dir / \"faiss.index\"\n",
    "    metadata_path = index_dir / \"metadata.pkl\"\n",
    "\n",
    "    texts = [d['chunk'] for d in docs]\n",
    "    metas = [{\"doc_id\": d[\"doc_id\"], \"chunk\" : d[\"chunk\"]} for d in docs]  \n",
    "\n",
    "    embeddings = embed_texts(texts)\n",
    "    dimension = embeddings.shape[1]\n",
    "\n",
    "    if index_path.exists():\n",
    "        index = faiss.read_index(str(index_path))\n",
    "        old_metadata = pickle.load(open(metadata_path, \"rb\"))\n",
    "        index.add(embeddings)\n",
    "        metas = old_metadata + metas\n",
    "    else:\n",
    "        index = faiss.IndexFlatL2(dimension)\n",
    "        index.add(embeddings)\n",
    "\n",
    "    faiss.write_index(index, str(index_path))\n",
    "    with open(metadata_path, \"wb\") as f:\n",
    "        pickle.dump(metas, f)\n",
    "\n",
    "    print(f\"Saved FAISS index with {index.ntotal} vectors.\")\n",
    "\n",
    "def ingest_folder(folder: Path= data_dir):\n",
    "    pdf_files = list(folder.glob(\"*.[Pp][Dd][Ff]\"))\n",
    "    all_docs = []\n",
    "    for pdf_file in pdf_files:\n",
    "        doc_id = pdf_file.name\n",
    "        print(f\"Processing {doc_id}...\")\n",
    "        text = read_pdf(str(pdf_file))\n",
    "        chunks = chunk_text(text)\n",
    "        for c in chunks:\n",
    "            all_docs.append({\"doc_id\": doc_id, \"chunk\": c})\n",
    "    if not all_docs:\n",
    "        print(\"No documents found to ingest.\")\n",
    "        return\n",
    "    build_faiss_index(all_docs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "608e6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load index and retrieve\n",
    "def load_faiss_index():\n",
    "    index_path = index_dir / \"faiss.index\"\n",
    "    metadata_path = index_dir / \"metadata.pkl\"\n",
    "    if not index_path.exists() or not metadata_path.exists():\n",
    "        raise FileNotFoundError(\"FAISS index or metadata not found. Please ingest data first.\")\n",
    "    index = faiss.read_index(str(index_path))\n",
    "    with open(metadata_path, \"rb\") as f:\n",
    "        metadata = pickle.load(f)\n",
    "    return index, metadata\n",
    "\n",
    "def embed_query(query: str):\n",
    "    emb = EMBED_NAME().encode([query], convert_to_numpy=True)\n",
    "    return emb.astype(\"float32\")\n",
    "\n",
    "def retrieve_similar_chunks(query: str, k=k):\n",
    "    index, metadata = load_faiss_index()\n",
    "    query_emb = embed_query(query)\n",
    "    distances, indices = index.search(query_emb, k)\n",
    "    results = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        if idx <0 or idx >= len(metadata):\n",
    "            continue\n",
    "        meta = metadata[idx]\n",
    "        results.append({\"score\": float(dist), \"doc_id\": meta.get(\"doc_id\"), \"chunk\": meta.get(\"chunk\")})\n",
    "\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbaaddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "def build_prompt(question: str, contexts: List[Dict]):\n",
    "      header =(\"You are an AI assistant helping users find information from provided document excerpts.If the answer is not in the context , say I don't know based on the provided documents,  be concise Use the following excerpts to answer the question as accurately as possible.\\n\\n\") \n",
    "      ctx_text = \"\\n\\n---\\n\\n\".join([f\"Source: {c['doc_id']}\\n\\n{c['chunk']}\" for c in contexts])\n",
    "      prompt = f\"{header}{ctx_text}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "      return prompt\n",
    "\n",
    "def call_ollama(prompt: str, model : str = OLLAMA_MODEL, max_tokens: int = 512, temperature: float = 0.0):\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(OLLAMA_API_URL, json=payload, timeout=150)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        return data.get(\"response\", \"\").strip()\n",
    "    except Exception as e:\n",
    "        print(\"Error calling Ollama API:\", str(e))\n",
    "        return\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "016767ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BGE model: BAAI/bge-small-en\n",
      "Successfully loaded BGE model.\n",
      "Answer: The main topic discussed in the document is a report on Pakistan's economic performance and current situation, including topics such as inflation, investment, agriculture, foreign exchange rates, economic resilience efforts, public health expenditure, educational reforms, and more. The document aims to provide an overview of the nation’s economic trends and challenges based on data from various sources and sectors within the government.\n",
      "\n",
      "Contexts:\n",
      "[{'chunk': 'strategic initiatives, based on data from the preceding fiscal '\n",
      "           'year and up to the third quarter of the current fiscal year. '\n",
      "           'Through rigorous analysis, the Survey aims to inform evidence- '\n",
      "           'based policymaking and enrich public discourse on Pakistan’s '\n",
      "           'economic trajectory. The timely preparation of this extensive '\n",
      "           'document would not have been possible without the collaboration '\n",
      "           'and support of numerous institutions. I sincerely appreciate all '\n",
      "           'Ministries, Divisions, Provincial Departments, and Agencies that '\n",
      "           'contributed essential data and inputs. In particular, I am '\n",
      "           'grateful to the Ministry of Planning, Development and Special '\n",
      "           'Initiatives, State Bank of Pakistan, Pakistan Bureau of '\n",
      "           'Statistics, Federal Board of Revenue, Securities and Exchange '\n",
      "           'Commission of Pakistan, and various wings of the Finance',\n",
      "  'doc_id': 'Highlights.pdf',\n",
      "  'score': 0.4203932583332062},\n",
      " {'chunk': 'zad (Adviser to the Finance Minister), Mr. Mohsin Mushtaq Chandana '\n",
      "           '(DG, DMO), Mr. Omar M. Khan (Adviser on Debt Management), and '\n",
      "           'other senior officers of the Finance Division, all of whom played '\n",
      "           'an important role in strengthening the final document. The '\n",
      "           'commitment and hard work of the officers and staff of the Economic '\n",
      "           'Adviser’s Wing in preparing this publication are especially '\n",
      "           'commendable. I hope this edition of the Pakistan Economic Survey '\n",
      "           'meets the expectations of policymakers, researchers, and the wider '\n",
      "           'public and continues to serve as a vital reference and knowledge '\n",
      "           'resource. Constructive feedback and suggestions for future '\n",
      "           'improvement are most welcome. Dr. Raja Hasan M. Mohsin Economic '\n",
      "           'Adviser PREFACE Islamabad, June, 2025 iii Global Economic Situaon '\n",
      "           'Growth and Investment Agriculture',\n",
      "  'doc_id': 'Highlights.pdf',\n",
      "  'score': 0.4452851414680481},\n",
      " {'chunk': 'ility of essential items. CHAPTER 07 Inflation 15 RS *: Jul-Apr ** '\n",
      "           ': April 2025/April 2024 Sensitive Price Indicator (SPI) 4.9% '\n",
      "           '(FY2025)* 30.2% (FY2024)* Wholesale Price Index (WPI) 2.2% '\n",
      "           '(FY2025)* 22.4% (FY2024)* Core: Urban 8.8% (FY2025)* 16.9% '\n",
      "           '(FY2024)* Rural 11.6% (FY2025)* 24.0% (FY2024)* Consumer Price '\n",
      "           'Index (CPI) 4.7% 26.0% (FY2024)* CPI Urban 5.7% (FY2025)* 26.3% '\n",
      "           '(FY2024)* CPI Rural 3.3% (FY2025)* 25.5% (FY2024)* FAO Food Price '\n",
      "           'Index ** Rs Rs Rs Rs 7.6% (FY2025)* Food: 1.1% (FY2025)* 26.8% '\n",
      "           '(FY2024)* Non-Food: 9.1% (FY2025)* 25.9% (FY2024)* Food: -1.5% '\n",
      "           '(FY2025)* 26.5% (FY2024)* Non-Food: 8.3% (FY2025)* 24.5% (FY2024)* '\n",
      "           'KEY INDICATORS 16 ■ The Current Account posted a surplus of US$ '\n",
      "           '1.9 billion during July–April FY2025, reversing a deficit of US$ '\n",
      "           '1.3 billion in the same period last yea',\n",
      "  'doc_id': 'Highlights.pdf',\n",
      "  'score': 0.4589774012565613},\n",
      " {'chunk': 'orks, strengthening institutional governance, and fostering '\n",
      "           'international collaborations to sustain economic resilience. This '\n",
      "           'Economic Survey is a testament to Pakistan’s resilience and '\n",
      "           'economic potential under diligent governance. I commend Mr. Imdad '\n",
      "           'Ullah Bosal (Secretary Finance), Dr. Imtiaz Ahmad (Chief '\n",
      "           'Economist, Ministry of Planning, Development & Special '\n",
      "           'Initiatives) and Dr. Raja Hasan M. Mohsin (Economic Adviser, '\n",
      "           'Ministry of Finance) and their dedicated teams for compiling this '\n",
      "           'important document. Islamabad, June, 2025 Senator Muhammad '\n",
      "           'Aurangzeb Minister for Finance and Revenue FOREWORD i Pakistan '\n",
      "           'Monument - Islamabad The Pakistan Economic Survey is the flagship '\n",
      "           'annual publication of the Ministry of Finance, providing a '\n",
      "           'comprehensive overview of the country’s economic performance d',\n",
      "  'doc_id': 'Highlights.pdf',\n",
      "  'score': 0.4679837226867676},\n",
      " {'chunk': 'p scheme; Rs 32.6 billion was released during July– April FY2025. '\n",
      "           '■ HEC launched the IT component of the World Bank-supported US$ '\n",
      "           '400 million Higher Education Development Programme, aiming to '\n",
      "           'upgrade Pakistan’s higher education technological infrastructure '\n",
      "           'significantly. CHAPTER 10 Education 21 Female: 52.8%Male: 68.0% '\n",
      "           'Private: 109Public: 160 0.8 (as % of GDP)Expenditure FY2025 '\n",
      "           '(Jul-Mar) Literacy Rate 60.6% Universities 269 Higher Education '\n",
      "           'Allocation 61.1 (Rs Billion) Ph.D Faculty Members 37.97% Rs KEY '\n",
      "           'INDICATORS 22 ■ The government is committed to Universal Health '\n",
      "           'coverage. The total public health expenditure during FY2024 '\n",
      "           'amounted to Rs 924.9 billion (0.9% of GDP) against Rs 843.2 '\n",
      "           'billion last year. A total of Rs 103.5 billion was allocated to '\n",
      "           'the health sector in PSDP for FY2025. ■ M/o',\n",
      "  'doc_id': 'Highlights.pdf',\n",
      "  'score': 0.47075262665748596}]\n"
     ]
    }
   ],
   "source": [
    "def generate_answer(question: str, top_: int = k):\n",
    "    contexts = retrieve_similar_chunks(question, k=top_)\n",
    "    prompt = build_prompt(question, contexts)\n",
    "    answer = call_ollama(prompt)\n",
    "    if not answer:\n",
    "        answer = \"Error: Ollama did not return output\"\n",
    "    return{\"answer\": answer.strip(), \"contexts\": contexts}\n",
    "\n",
    "#demo \n",
    "question = \"What is the main topic discussed in the document?\"\n",
    "result = generate_answer(question)\n",
    "print(\"Answer:\", result[\"answer\"])\n",
    "print(\"\\nContexts:\")\n",
    "pprint.pprint(result[\"contexts\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0e74dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index exists: False\n",
      "Metadata exists: False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(\"Index exists:\",Path(\"vector_store/faiss.index\").exists())\n",
    "print(\"Metadata exists:\",Path(\"vector_store/metadata.pkl\").exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23cdbf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Highlights.pdf...\n",
      "Loading BGE model: BAAI/bge-small-en\n",
      "Successfully loaded BGE model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:16<00:00,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FAISS index with 65 vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ingest_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce2962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
